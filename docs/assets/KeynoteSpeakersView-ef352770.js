import{j as h,G as v,k as c,l as u,c as g,q as i,D as s,z as d,u as t,O as f,Q as m,A as b,_ as y,S as E,av as w,E as l,aw as n}from"./index-fecb07c4.js";const I=h({direction:{type:String,values:["horizontal","vertical"],default:"horizontal"},contentPosition:{type:String,values:["left","center","right"],default:"center"},borderStyle:{type:v(String),default:"solid"}}),S=c({name:"ElDivider"}),_=c({...S,props:I,setup(o){const r=o,e=u("divider"),p=g(()=>e.cssVar({"border-style":r.borderStyle}));return(a,H)=>(i(),s("div",{class:d([t(e).b(),t(e).m(a.direction)]),style:b(t(p)),role:"separator"},[a.$slots.default&&a.direction!=="vertical"?(i(),s("div",{key:0,class:d([t(e).e("text"),t(e).is(a.contentPosition)])},[f(a.$slots,"default")],2)):m("v-if",!0)],6))}});var k=y(_,[["__file","/home/runner/work/element-plus/element-plus/packages/components/divider/src/divider.vue"]]);const D=E(k);const A={},T={class:"keynote-speakers"},C=n('<div class="title1 font-merri" data-v-2130b2a2>Keynote Speakers</div><div class="title2 section-title" data-v-2130b2a2>Joseph Sifakis, Verimag</div><div class="content" data-v-2130b2a2><div class="pa" data-v-2130b2a2><p data-v-2130b2a2><span class="bold" data-v-2130b2a2>Keynote: </span><span class="thin" data-v-2130b2a2> Trustworthy Intelligent Systems – A Daunting Challenge</span></p></div><div class="pa" data-v-2130b2a2><p data-v-2130b2a2><span class="bold" data-v-2130b2a2>Abstract: </span><span class="thin italic" data-v-2130b2a2> Systems engineering today is torn between two contradictory trends. On the one hand, the construction of intelligent systems, capable of situation awareness and adaptive decision-making through the use of AI-based components; on the other, the need for trustworthiness guarantees despite the non-explicability of AI components. The situation is exacerbated by the need for increasingly complex and integrated heterogeneous systems, and by the fact that in the current debate on &quot;safe AI&quot;, key players in the field are promoting approaches that break with the technical safety concept of systems engineering.</span></p><p class="thin italic indent" data-v-2130b2a2>We consider that a system is explainable if it is possible to characterize its relevant behavior by faithful models that lend themselves to analysis and provide a basis for understanding. We argue that AI will remain largely inexplicable. Ignoring this limitation by ascribing anthropomorphic properties to AI systems is technically untenable.</p><p class="thin italic indent" data-v-2130b2a2>We need rigorous system design methodologies that integrate model-based and data-driven AI te chniques, enabling in particular the construction of reliable systems integrating unreliable AI components. These methodologies will be characterized by the following important changes: </p><ul data-v-2130b2a2><li class="thin italic indent" data-v-2130b2a2>Breaking with the idea that system can be guaranteed trustworthy at design time. Instead, systems must be designed to evolve, with no endpoint in their evolution, using computational intelligence, monitoring techniques and over-the-air upgrades.</li><li class="thin italic indent" data-v-2130b2a2>A shift from verification to empirical validation using test and simulation, which in principle does not allow confidence levels achieved using model-based methods. </li><li class="thin italic indent" data-v-2130b2a2>A better integration of design for dependability into the system development cycle, by jointly addressing safety and security issues, and relying heavily on automated tools.</li></ul><p class="thin italic indent" data-v-2130b2a2>We advocate the need for a new foundation for system design that responds to these needs, leveraging knowledge management to compensate for weaknesses arising from the obsolescence of model-based techniques.</p></div><div data-v-2130b2a2><p data-v-2130b2a2><span class="bold" data-v-2130b2a2>Bio: </span><span class="thin" data-v-2130b2a2> Professor Joseph Sifakis is Emeritus Research Director at Verimag. He has been a full professor at Ecole Polytechnique Fédérale de Lausanne (EPFL) for the period 2011-2016. He is the founder of the Verimag laboratory in Grenoble, a leading laboratory in the area of safety critical systems that he directed for 13 years.</span></p><p class="thin italic indent" data-v-2130b2a2>Joseph Sifakis has made significant and internationally recognized contributions to the design of trustworthy systems in many application areas, including avionics and space systems, telecommunications, and production systems. His current research focuses on autonomous systems, in particular self-driving cars and autonomous telecommunication systems. In 2007, he received the Turing Award, recognized as the &quot;highest distinction in computer science&quot;, for his contribution to the theory and application of model checking, the most widely used system verification technique. </p><p class="thin italic indent" data-v-2130b2a2>Joseph Sifakis is a member of six academies and a frequent speaker at international scientific, technical and public forums.</p></div></div>',3),N=n('<div class="title2 section-title" data-v-2130b2a2>Zheng Zheng, Beihang University</div><div class="content" data-v-2130b2a2><div class="pa" data-v-2130b2a2><p data-v-2130b2a2><span class="bold" data-v-2130b2a2>Keynote: </span><span class="thin" data-v-2130b2a2> Bugs with &quot;intelligence&quot; and intelligence with bugs</span></p></div><div class="pa" data-v-2130b2a2><p data-v-2130b2a2><span class="bold" data-v-2130b2a2>Abstract: </span><span class="thin italic" data-v-2130b2a2> Fault triggering conditions are usually complex, involving not only the workload but also the interaction with execution environment. According to the complexity of fault activation and/or error propagation conditions, bugs were classified into Bohrbugs and Mandelbugs, in which the activation and/or error propagation of Mandelbugs are complex. They make the system show a phenomenon of “intelligence”, exhibiting chaotic and even non-deterministic behavior during operation. In the first part of this presentation, the characteristics of this type of bugs are illustrated by the empirical studies on several traditional software systems.</span></p><p class="thin italic indent" data-v-2130b2a2>In the second part of this presentation, we will investigate the bug characteristics and root causes of different bug types in three widely used deep learning frameworks and five popular deep learning compilers, and will compare it with those in traditional software systems. Nowadays, various DL models with different architectures, such as CNN, RNN and GNN have been designed to deal with different artificial intelligence tasks. As the foundation to support the training process and runtime inference, multiple popular DL frameworks have been developed so far. However, it is still a challenge for DL frameworks to handle diverse hardware-specific transformations and DL model deployment across various target devices. To address this problem, several popular DL compilers have been proposed. The presentation in this part can help researchers understand bugs in the process of constructing and deploying DL models.</p></div><div data-v-2130b2a2><p data-v-2130b2a2><span class="bold" data-v-2130b2a2>Bio: </span><span class="thin" data-v-2130b2a2> Zheng Zheng is a professor at Beihang University and the deputy dean of School of Automation Science and Electrical Engineering. His research work is primarily concerned with software reliability and testing. Recently, He paid more attention on the intelligent software reliability engineering. He is co-author of over 100 journal and conference publications, including IEEE TDSC, IEEE TIFS, IEEE TSE, IEEE TR, IEEE TSC, JSS and so on. He serves for IEEE PRDC2019, IEEE DASC 2019, IEEE ISSRE 2020, IEEE QRS 2021 as PC Co-Chairs, as well as WoSAR 2019, DeIS 2020 and DeIS 2021 as General Co-Chairs. He is Editor-in-chief of Atlantis Highlights in Engineering (Springer Nature), Associate Editor of IEEE TR (2021- ), Elsevier KBS (2018- ) and Springer IJCIS (2012- ) and Guest Editor of IEEE TDSC (2021). He is IEEE Senior Member and IEEE CIS Emerging Technologies TC member.</span></p></div></div>',2),x=n('<div class="title2 section-title" data-v-2130b2a2>Domenico Cotrone, University of Naples Federico II</div><div class="content" data-v-2130b2a2><div class="pa" data-v-2130b2a2><p data-v-2130b2a2><span class="bold" data-v-2130b2a2>Keynote: </span><span class="thin" data-v-2130b2a2> Unveiling the Veil: Towards the Trustworthiness of AI Code Generators</span></p></div><div class="pa" data-v-2130b2a2><p data-v-2130b2a2><span class="bold" data-v-2130b2a2>Abstract: </span><span class="thin italic" data-v-2130b2a2> Nowadays, AI code generators have emerged as powerful tools transforming the software development landscape. These tools promise accelerated productivity and efficiency, but they also raise crucial questions regarding the trustworthiness of the code they produce. This keynote talk delves into the heart of this critical issue, aiming to provide a comprehensive understanding of the topics related to the trustworthiness of AI code generators, focusing on the security and robustness aspects of these AI-powered solutions.</span></p><p class="thin italic indent" data-v-2130b2a2>Beginning with an in-depth examination of the security and robustness landscape surrounding AI code generators, the talk will dissect the common threats and risks associated with new technology impacting our everyday lives. From adversarial inputs to poisoning attacks, understanding these potential pitfalls is crucial for developers and organizations alike.</p></div><div data-v-2130b2a2><p data-v-2130b2a2><span class="bold" data-v-2130b2a2>Bio: </span><span class="thin" data-v-2130b2a2> Domenico Cotroneo is a Full Professor at the Department of Electrical Engineering and Information Technology, University of Naples Federico II. He is also an IEEE Senior Member. He has served on the Technical Program Committee of important conferences on Dependability and Software Reliability, eg., IEEE/IFIP DSN, IEEE SRDS, Safecomp, IEEE ISSRE, and IEEE ICDS. Domenico’s research activities cover the following areas: dependability assessment of complex software systems, software fault injection, and software performance degradation analysis.</span></p></div></div><div class="title2 section-title" data-v-2130b2a2>Ryan Cotterell, ETH Zürich</div><p class="pa-content p" data-v-2130b2a2>TBD</p>',4);function q(o,r){const e=D;return i(),s("div",T,[C,l(e),N,l(e),x])}const P=w(A,[["render",q],["__scopeId","data-v-2130b2a2"]]);export{P as default};
